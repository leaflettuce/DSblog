{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've wanted to get more practice with natural language processing, so I grabbed a dataset of Wikipedia comments from a past Kaggle challenge to attempt to classify toxicity of each comment. Train data was a collection of over 150k comments connected to user-defined classifications of 'toxic', 'severe toxic', 'obscene', 'insult', 'threat', 'hate'. Here's the process I took to create a model which identifies these particular classsifications of future comments!\n",
    "\n",
    "First is to import libraries we'll be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from above, I opted to go with a naive bayes model for the final classification. While a few other classifiers may have been suitable as well (DT or RF in particular), I wanted to use this primarily as practice for nlp, and as such only trained and fit one model without tweaking. \n",
    "\n",
    "Data imports next..There were way too large and I therefore won't have them included on the site//in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set working dir\n",
    "os.chdir('D:/Projects/Kaggle/toxic_comments')\n",
    "\n",
    "# import\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "df_test_labs = pd.read_csv(\"data/test_labels.csv\")\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_sub = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So first step for the actual preprocessing is to create a corpus of the words from each comment. I iterate through kine of the csv, grab the comment, cut the punctionation, split into a list, stem each word, connect them back into a str, and finally append it to the corpus.\n",
    "\n",
    "NOTE: The data was too large for my comp to deal with all at once. I kept running into memory issues, so I ended up cutting the data and using about 1/3 of it to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#init corpus\n",
    "corpus = []\n",
    "\n",
    "#loop through df and clean comments\n",
    "for i in range(0, 50000):\n",
    "    #reg_exp to replace anything not text to a space and drop to lower case\n",
    "    comment = re.sub('[^a-zA-Z]', ' ', df_train['comment_text'][i]).lower()\n",
    "    #split into list for processing\n",
    "    comment = comment.split()\n",
    "    #check for stopwords and remove\n",
    "    comment = [word for word in comment if not word in set(stopwords.words('english'))]\n",
    "    #stem the word!\n",
    "    ps = PorterStemmer()\n",
    "    comment = [str(ps.stem(word)) for word in comment]\n",
    "    #back to string\n",
    "    comment = ' '.join(comment)\n",
    "    corpus.append(comment)\n",
    "    #track progress\n",
    "    if i%1000 == 0:\n",
    "        print((float(i)/len(df_train))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I next took the corpus and vectorized it into a sparse matrix. This provides the matrix to train off of which is suitable for NB or most other classifiers.  Of course an idenetifer is required for the train, so I also bring in each classification in here as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bag of Words Model - sparse matrix (tokenize)\n",
    "cv = CountVectorizer(max_features = 25000)   #max words to store \n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y_tox = df_train.iloc[0:50000,2].values\n",
    "y_sev_tox = df_train.iloc[0:50000,3].values\n",
    "y_obs = df_train.iloc[0:50000,4].values\n",
    "y_threat = df_train.iloc[0:50000,5].values\n",
    "y_insult = df_train.iloc[0:50000,6].values\n",
    "y_hate = df_train.iloc[0:50000,7].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as I'm looking to classify 6 different possibilities rather than just one, I ended up creating two dictionaries to store the targets and models in, respectively. I use a list of the dict keys to iterate through them both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#model for each predicted type\n",
    "tests = {'y_tox' : y_tox, \n",
    "         'y_sev_tox' : y_sev_tox, \n",
    "         'y_obs' : y_obs, \n",
    "         'y_threat' : y_threat, \n",
    "         'y_insult' : y_insult, \n",
    "         'y_hate' : y_hate}\n",
    "\n",
    "models = {'y_tox' : GaussianNB(), \n",
    "          'y_sev_tox' : GaussianNB(),\n",
    "          'y_obs' : GaussianNB(),\n",
    "          'y_threat' : GaussianNB(),\n",
    "          'y_insult' : GaussianNB(),\n",
    "          'y_hate' : GaussianNB()}\n",
    "\n",
    "preds = {}\n",
    "\n",
    "test_names = ['y_tox', 'y_sev_tox', 'y_obs', 'y_threat', 'y_insult', 'y_hate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally for the training of the model, I iterate through each target classification and train the sparse matrix(X) against them. \n",
    "\n",
    "While I'm not bringing the data into this notebook, the accuracy aonfusion matrix values were pretty solid. Of the six classifications, NB averages an accuracy or around .94."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in test_names:\n",
    "    #test_train split (toxic)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, tests[i], test_size = 0.05, random_state = 42)\n",
    "    \n",
    "    #Train Model (naive bayes)\n",
    "    models[i].fit(X_train, y_train)\n",
    "\n",
    "    #predict\n",
    "    preds[i] = models[i].predict(X_test)\n",
    "    \n",
    "    #review model\n",
    "    print(i)\n",
    "    print(confusion_matrix(y_test, preds[i]))\n",
    "    print(accuracy_score(y_test, preds[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright,  with the model made its simply a matter of running the test data through the pipeline!\n",
    "\n",
    "First: create the corpus to make another sparse matrix with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN TEST THROUGH PIPELINE\n",
    "test_corpus = []\n",
    "for i in range(130000, 153164):\n",
    "    #reg_exp to replace anything not text to a space and drop to lower case\n",
    "    comment = re.sub('[^a-zA-Z]', ' ', df_test['comment_text'][i]).lower()\n",
    "    #split into list for processing\n",
    "    comment = comment.split()\n",
    "    #check for stopwords and remove\n",
    "    comment = [word for word in comment if not word in set(stopwords.words('english'))]\n",
    "    #stem the word!\n",
    "    ps = PorterStemmer()\n",
    "    comment = [str(ps.stem(word)) for word in comment]\n",
    "    #back to string\n",
    "    comment = ' '.join(comment)\n",
    "    test_corpus.append(comment)\n",
    "    #track progress\n",
    "    if i%1000 == 0:\n",
    "        print((float(i)/50000)*100)\n",
    "        \n",
    "#kaggle test array    \n",
    "X_kaggle = cv.transform(test_corpus).toarray()\n",
    "kaggle_preds = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As (again) we're predicting 6 target possibilities, I ran a for each loop to hit each model and predict the expected binary yes/no of each comment classificaiton. Predictions were stored in another dictionary for the same reasons as all the others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#predict probability for each\n",
    "for i in test_names:\n",
    "    print i\n",
    "    kaggle_preds[i] = models[i].predict(X_kaggle)\n",
    "     \n",
    "#list out in sample sub\n",
    "sample_sub = pd.DataFrame(df_sub.iloc[130000:,0])\n",
    "sample_sub = sample_sub.reset_index(drop=True)\n",
    "sample_placement = pd.DataFrame(kaggle_preds)\n",
    "sample_placement = sample_placement.reindex_axis(['y_tox','y_sev_tox', 'y_obs','y_threat', 'y_insult', 'y_hate'], axis=1)\n",
    "sample_sub = sample_sub.join(sample_placement)\n",
    "sample_sub = sample_sub.rename(columns={'y_tox': 'toxic', 'y_sev_tox': 'sever_toxic',\n",
    "                                        'y_obs': 'obscene', 'y_threat': 'threat', \n",
    "                                        'y)insult': 'insult', 'y_hate': 'indentity_hate'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with that, all that remains is to write the rewritten sample_sub into a csv and upload to Kaggle. Fun Fact: I kept running into memory issues on my comp running this, so I had run the transforming and prediction steps in 4 different segments... each of these taking about 45 minutes to run. \n",
    "\n",
    "Kaggle results were decent but nothing special. Then again, I fit only one model, didn;'t compare it to any others, and didn't attempt any param tuning, dimensionality reduction, standardization, or other steps which could have helped out here.  Again, it was to practice nlp (mainly with the nltk kit). With that in mind, I fele quite sucessful in this project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
